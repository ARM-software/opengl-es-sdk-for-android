<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<title>OpenGL ES SDK for Android: Introduction to compute shaders</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function()
{ (i[r].q=i[r].q||[]).push(arguments)}
,i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-35797182-1', 'auto');
ga('send', 'pageview');
</script>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
  $(document).ready(initResizable);
  $(window).load(resizeHeight);
</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { init_search(); });
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="stylesheet.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0" width="100%">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectlogo"><img alt="Logo" src="top_banner.bmp"/></td>
  <td style="padding-left: 0.5em;">
   <div id="projectname">OpenGL ES SDK for Android
<span id="armdevcenter"><a href="https://developer.arm.com/">ARM Developer Center</a></span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.11 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Home</span></a></li>
      <li class="current"><a href="pages.html"><span>Pages</span></a></li>
      <li><a href="namespaces.html"><span>Namespaces</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(document).ready(function(){initNavTree('computeIntro.html','');});
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">Introduction to compute shaders </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p>This document will give you an introduction to compute shaders in OpenGL ES 3.1, how they fit into the rest of OpenGL ES and how you can make use of it in your application. Using compute shaders effectively requires a new mindset where parallel computation is exposed more explicitly to developers. With this explicitness, various new primitives are introduced which allows compute shader threads to share access to memory and synchronize execution.</p>
<dl class="section note"><dt>Note</dt><dd>This tutorial does not include a particular code sample outside the snippets provided here. This document is intended to be read before digging deep into the more involved compute shader samples.</dd></dl>
<h1><a class="anchor" id="computeModel"></a>
The compute model, implicit vs. explicit parallelism</h1>
<p>For the most part, computer graphics is a so called "embarrassingly parallel" problem. If we look at drawing a scene we can process all vertices and the resulting fragments in parallel and separately. Getting good parallelism for such a case is fairly straight forward, and does not require much from an OpenGL ES application. GPUs are designed to handle these workloads well.</p>
<p>A good side effect of embarrassingly parallel computation is that from an API standpoint, there is no need to explicitly state the number of threads needed for a task and manage them manually. We only provide shader code for the task that is to be run in parallel.</p>
<div class="fragment"><div class="line"><span class="keywordflow">for</span> (<span class="keywordtype">int</span> i = 0; i &lt; NUMBER_OF_INVOCATIONS; i++)</div><div class="line">{</div><div class="line">    run_shader(output[i], input[i]);</div><div class="line">}</div></div><!-- fragment --><p>We do not need to care how the loop is implemented, or in which order the loop is executed. We only implement run_shader(), or in our case, our shader code. In compute terms, the loop body, <code>run_shader()</code>, is commonly called the "kernel".</p>
<p>Before compute shaders, there were multiple ways to expose embarrassingly parallel computation in OpenGL ES. A common way to perform computation is by rasterizing a quad and performing arbitrary computation in the fragment shader. The results can then be written to a texture. Another approach is to use transform feedback to perform arbitrary computation in the vertex shader.</p>
<p>A common theme in vertex and fragment shading is that once the shader starts executing, it is already known where the shader will write data and the shader invocation has no knowledge of other shader invocations running in parallel. In vertex shading, our input is vertex attributes and we output varyings and <code>gl_Position</code>. For fragment, we take interpolated varyings as input and output one or multiple colors. Using textures and uniform buffer objects, we are able to read from arbitrary memory in vertex and fragment, but we are still only allowed to write to one specific location.</p>
<p>Moving to compute, we have no notion of vertex attribute, varyings, or output colors. Once a compute thread starts executing, it has no prior knowledge of where it will read data from nor where it will write to. Since every compute thread executes the same kernel code, we need some way for threads to do different things. The approach that compute APIs have taken is to give each thread a unique identifier.</p>
<p>Consider the difference between:</p>
<div class="fragment"><div class="line"><span class="preprocessor">#version 300 es</span></div><div class="line"></div><div class="line"><span class="comment">// Your typical transform feedback vertex shader.</span></div><div class="line">in <a class="code" href="structvec3.html">vec3</a> aPosition;  <span class="comment">// Fixed input.</span></div><div class="line">out <a class="code" href="structvec3.html">vec3</a> <a class="code" href="tutorials_2_simple_triangle_2jni_2_native_8cpp.html#a8ada611d96d8e1cfb505c37519d64cf3">vPosition</a>; <span class="comment">// Fixed output. Outputs to transform feedback.</span></div><div class="line"></div><div class="line"><span class="keywordtype">void</span> <a class="code" href="scan_8cs.html#acdef7a1fd863a6d3770c1268cb06add3">main</a>()</div><div class="line">{</div><div class="line">    <a class="code" href="structvec3.html">vec3</a> next_position = compute_next_position(aPosition);</div><div class="line">    gl_Position = <a class="code" href="structvec4.html">vec4</a>(next_position, 1.0);</div><div class="line">    vPosition = next_position;</div><div class="line">}</div></div><!-- fragment --><p>and</p>
<div class="fragment"><div class="line"><span class="preprocessor">#version 310 es</span></div><div class="line"><span class="comment">// Details left blank ...</span></div><div class="line"><span class="keywordtype">void</span> <a class="code" href="scan_8cs.html#acdef7a1fd863a6d3770c1268cb06add3">main</a>()</div><div class="line">{</div><div class="line">    uint index = gl_GlobalInvocationID.x; <span class="comment">// Identify the thread, use it to lookup some data.</span></div><div class="line">    positions[<a class="code" href="gl2ext_8h.html#a57f14e05b1900f16a2da82ade47d0c6d">index</a>] = compute_next_position(positions[index]);</div><div class="line">}</div></div><!-- fragment --><p>In the latter case, we explicitly state that we want to process elements independently, where in the first, we're forced to do so by design. As we see, transform feedback can be considered a special case of compute where inputs and output are mapped one-to-one.</p>
<h2><a class="anchor" id="computeWorkGroups"></a>
Work groups in compute</h2>
<div class="image">
<img src="compute_dispatch.png" alt="compute_dispatch.png"/>
<div class="caption">
A compute dispatch</div></div>
<p> A typical compute job can span hundreds of thousands of threads, just like a quad being rasterized to a full screen can easily cover millions of pixels. It is clear that even a GPU cannot feasibly keep track of so many threads at one time. We do not have enough hardware for so many threads to execute at the same time.</p>
<p>Instead, we subdivide our threads into work groups which consist of a fixed number of threads. This is a smaller collection of threads that can run in parallel. Individual work groups however, are completely independent. A valid implementation could now look like</p>
<div class="fragment"><div class="line"><span class="keywordflow">for</span> (<span class="keywordtype">int</span> <a class="code" href="gl2ext_8h.html#afb1b07e1b25035d41d60fb2c03d507e6">w</a> = 0; <a class="code" href="gl2ext_8h.html#afb1b07e1b25035d41d60fb2c03d507e6">w</a> &lt; NUM_WORK_GROUPS; <a class="code" href="gl2ext_8h.html#afb1b07e1b25035d41d60fb2c03d507e6">w</a>++)</div><div class="line">{</div><div class="line">    <span class="comment">// Guaranteed to run in parallel.</span></div><div class="line">    parallel_for (<span class="keywordtype">int</span> i = 0; i &lt; THREADS_IN_WORK_GROUP; i++)</div><div class="line">    {</div><div class="line">        execute_compute_thread(<a class="code" href="gl2ext_8h.html#afb1b07e1b25035d41d60fb2c03d507e6">w</a>, i);</div><div class="line">    }</div><div class="line">}</div></div><!-- fragment --><p>The number of threads in the work group is defined in the compute shader itself. To do this, we use a layout qualifier as such:</p>
<div class="fragment"><div class="line"><span class="preprocessor">#version 310 es</span></div><div class="line"><span class="comment">// NUM_X * NUM_Y * NUM_Z threads per work group.</span></div><div class="line"><a class="code" href="scan_8cs.html#abc5bc4dfe74a37a3a6850b9a15630dc7">layout</a>(local_size_x = NUM_X, local_size_y = NUM_Y, local_size_z = NUM_Z) in;</div><div class="line"><span class="comment">// Rest of shader code here.</span></div></div><!-- fragment --><p>In OpenGL ES, implementations must support at least 128 threads in a work group. It is possible to check <code>glGetIntegerv(GL_MAX_COMPUTE_WORK_GROUP_INVOCATIONS)</code> in run-time to get implementation-specific limits.</p>
<div class="image">
<img src="compute_work_group.png" alt="compute_work_group.png"/>
<div class="caption">
A compute work group</div></div>
 <h2><a class="anchor" id="computeIdentification"></a>
Identifying compute threads</h2>
<p>In OpenGL ES compute shaders, there are various ways for individual threads to get some unique identification.</p>
<div class="fragment"><div class="line">in uvec3 gl_NumWorkGroups;        <span class="comment">// Check how many work groups there are. Provided for convenience.</span></div><div class="line">in uvec3 gl_WorkGroupID;          <span class="comment">// Check which work group the thread belongs to.</span></div><div class="line">in uvec3 gl_LocalInvocationID;    <span class="comment">// Within the work group, get a unique identifier for the thread.</span></div><div class="line">in uvec3 gl_GlobalInvocationID;   <span class="comment">// Globally unique value across the entire compute dispatch. Short-hand for gl_WorkGroupID * gl_WorkGroupSize + gl_LocalInvocationID;</span></div><div class="line">in uint  gl_LocalInvocationIndex; <span class="comment">// 1D version of gl_LocalInvocationID. Provided for convenience.</span></div></div><!-- fragment --><p>Note the three dimensional values. In compute applications, it is often desirable to organize the work in more than one dimension. For image processing, it makes sense to use two dimensions, while processing volumetric 3D data makes sense to do using three dimensions.</p>
<p>It's important to note that this work group scheme is not new. This is the common model used by all major compute APIs, and skills learned by coding against this model can be applied to APIs like OpenCL as well. If you have used other compute APIs in the past, the OpenGL model should feel familiar.</p>
<h1><a class="anchor" id="compileCompileAndRun"></a>
Compiling and executing a compute shader</h1>
<p>Compute shaders are still shaders just like fragment and vertex shaders. The difference however, is that compute shaders are single-stage. You cannot link a compute shader with a vertex shader for example.</p>
<p>To compile and link a compute program, we can do something like this </p><div class="fragment"><div class="line"><a class="code" href="gl2ext_8h.html#adda687347282e5405e89b4fc19a1f8e2">GLuint</a> <a class="code" href="gl2ext_8h.html#adffcc51f3ade9f7911b0db30601322f6">program</a> = glCreateProgram();</div><div class="line"><a class="code" href="gl2ext_8h.html#adda687347282e5405e89b4fc19a1f8e2">GLuint</a> shader = glCreateShader(GL_COMPUTE_SHADER);</div><div class="line">glShaderSource(shader, ...);</div><div class="line">glCompileShader(shader);</div><div class="line">glAttachShader(program, shader);</div><div class="line">glLinkProgram(program);</div></div><!-- fragment --><p>To execute a compiled shader, it works similarly to regular draw calls.</p>
<div class="fragment"><div class="line">glUseProgram(program); <span class="comment">// Compute shader program.</span></div><div class="line">glDispatchCompute(work_groups_x, work_groups_y, work_groups_z);</div></div><!-- fragment --><p>We explicitly state how many work groups we want to dispatch. The number of work groups will be <code>work_groups_x * work_groups_y * work_groups_z</code> organized in three dimensions as we specify ourselves.</p>
<p>Conceptually, this compute job runs asynchronous with the rest of OpenGL ES, and we will later look into how we synchronize with the rest of OpenGL ES.</p>
<h1><a class="anchor" id="computeSSBO"></a>
Reading and writing data to buffer objects</h1>
<p>While OpenGL ES has many different buffer types, there were no buffer types which could support fully random access writing. <a class="el" href="class_shader.html">Shader</a> storage buffer objects, or SSBO for short is the new general purpose buffer object in OpenGL ES. Implementations must support SSBOs of at least 128 MiB, which is a tremendous increase compared to the 16 KiB that uniform buffer objects must support.</p>
<h2><a class="anchor" id="computeBindingSSBO"></a>
Binding an SSBO</h2>
<p>Just like uniform buffer objects, SSBOs are bound in an indexed way as a shader can have multiple SSBOs in use.</p>
<div class="fragment"><div class="line">glBindBufferBase(GL_SHADER_STORAGE_BUFFER, index, buffer_object);</div><div class="line"></div><div class="line"><span class="comment">// In shader</span></div><div class="line"><a class="code" href="scan_8cs.html#abc5bc4dfe74a37a3a6850b9a15630dc7">layout</a>(binding = index) <a class="code" href="gl2ext_8h.html#a7fc54503e1a1cf98d128b839ebc0b4d0">buffer</a> <a class="code" href="namespace_g_l_f_f_t.html#ab2687fef8a775901f5fb093657631cb1ae5acf46f7696870f1a14d4ee79a846c0">SSBO</a> {</div><div class="line">    ...</div><div class="line">};</div></div><!-- fragment --><p>To create an SSBO and upload data to it, use <code>glBindBuffer()</code> as normal.</p>
<div class="fragment"><div class="line">glGenBuffers(1, &amp;ssbo);</div><div class="line">glBindBuffer(GL_SHADER_STORAGE_BUFFER, ssbo);</div><div class="line">glBufferData(GL_SHADER_STORAGE_BUFFER, ...);</div></div><!-- fragment --><dl class="section note"><dt>Note</dt><dd>SSBOs are not special. Any OpenGL buffer can be bound to a <code>GL_SHADER_STORAGE_BUFFER</code> target, no matter how they were originally created.</dd></dl>
<h2><a class="anchor" id="computestd430"></a>
Layout std430, new and better std140</h2>
<p>A problem with using e.g. uniform buffer objects is that the binary layout for CPU and GPU must be the same. std140 layout is the standard packing layout that is guaranteed to be the same for every implementation which makes it more maintainable and easy to use uniform buffer objects. std140 has some deficiencies however. One major problem with std140 is that arrays of scalars cannot be tightly packed. E.g. a <code>float array[1024];</code> will have element packing like a <code><a class="el" href="structvec4.html">vec4</a></code>, which quadruples the memory requirements. The workaround for that has been always packing in vec4s, but if the underlying data is inherently scalar, such workarounds are at best annoying.</p>
<p>std430 improves packing, and ensures that scalar arrays can be tightly packed. std430 is only available for SSBOs.</p>
<div class="fragment"><div class="line"><span class="preprocessor">#version 310 es</span></div><div class="line"><a class="code" href="scan_8cs.html#abc5bc4dfe74a37a3a6850b9a15630dc7">layout</a>(std430) <a class="code" href="gl2ext_8h.html#a7fc54503e1a1cf98d128b839ebc0b4d0">buffer</a>; <span class="comment">// Sets the default layout for SSBOs.</span></div><div class="line"></div><div class="line"><a class="code" href="scan_8cs.html#abc5bc4dfe74a37a3a6850b9a15630dc7">layout</a>(binding = 0) buffer <a class="code" href="namespace_g_l_f_f_t.html#ab2687fef8a775901f5fb093657631cb1ae5acf46f7696870f1a14d4ee79a846c0">SSBO</a> {</div><div class="line">    <span class="keywordtype">float</span> <a class="code" href="gl2ext_8h.html#a740d7f00b044f54a556c7208e01f9f02">data</a>[]; <span class="comment">// This array can now be tightly packed.</span></div><div class="line">};</div></div><!-- fragment --><h2><a class="anchor" id="computeUnsizedArrays"></a>
Unsized arrays in SSBOs</h2>
<p>When processing large amounts of data, it is often unknown in the shader itself how large a buffer object really is. In other buffer objects, we typically have to give it a size anyways, like</p>
<div class="fragment"><div class="line"><a class="code" href="scan_8cs.html#abc5bc4dfe74a37a3a6850b9a15630dc7">layout</a>(std140, binding = 0) <a class="code" href="_compute_particles_2jni_2common_2glutil_8cpp.html#a2c5c3c4ce30783b590dd30b1060b7b38">uniform</a> UBO {</div><div class="line">    SomeStruct elements[MAX_ELEMENTS];</div><div class="line">};</div></div><!-- fragment --><p>With SSBOs, this restriction is lifted, and we can declare the last member of a struct without size.</p>
<div class="fragment"><div class="line"><a class="code" href="scan_8cs.html#abc5bc4dfe74a37a3a6850b9a15630dc7">layout</a>(std430, binding = 0) <a class="code" href="gl2ext_8h.html#a7fc54503e1a1cf98d128b839ebc0b4d0">buffer</a> <a class="code" href="namespace_g_l_f_f_t.html#ab2687fef8a775901f5fb093657631cb1ae5acf46f7696870f1a14d4ee79a846c0">SSBO</a> {</div><div class="line">    SomeStruct elements[];</div><div class="line">};</div></div><!-- fragment --><p>It is possible to query the number of elements during shader execution using <code>elements.length()</code> like any other GLSL array. The length parameter is derived from the buffer that is bound to the binding point.</p>
<h2><a class="anchor" id="computeHelloWorld"></a>
Hello Compute World</h2>
<p>To give the minimally useful compute shader, let's assume we want to do an element-wise multiplies.</p>
<div class="fragment"><div class="line"><span class="preprocessor">#version 310 es</span></div><div class="line"><a class="code" href="scan_8cs.html#abc5bc4dfe74a37a3a6850b9a15630dc7">layout</a>(local_size_x = 128) in;</div><div class="line"><a class="code" href="scan_8cs.html#abc5bc4dfe74a37a3a6850b9a15630dc7">layout</a>(std430) <a class="code" href="gl2ext_8h.html#a7fc54503e1a1cf98d128b839ebc0b4d0">buffer</a>;</div><div class="line"></div><div class="line"><a class="code" href="scan_8cs.html#abc5bc4dfe74a37a3a6850b9a15630dc7">layout</a>(binding = 0) writeonly buffer Output {</div><div class="line">    <a class="code" href="structvec4.html">vec4</a> elements[];</div><div class="line">} output_data;</div><div class="line"></div><div class="line"><a class="code" href="scan_8cs.html#abc5bc4dfe74a37a3a6850b9a15630dc7">layout</a>(binding = 1) readonly <a class="code" href="gl2ext_8h.html#a7fc54503e1a1cf98d128b839ebc0b4d0">buffer</a> Input0 {</div><div class="line">    <a class="code" href="structvec4.html">vec4</a> elements[];</div><div class="line">} input_data0;</div><div class="line"></div><div class="line"><a class="code" href="scan_8cs.html#abc5bc4dfe74a37a3a6850b9a15630dc7">layout</a>(binding = 2) readonly <a class="code" href="gl2ext_8h.html#a7fc54503e1a1cf98d128b839ebc0b4d0">buffer</a> Input1 {</div><div class="line">    <a class="code" href="structvec4.html">vec4</a> elements[];</div><div class="line">} input_data1;</div><div class="line"></div><div class="line"><span class="keywordtype">void</span> <a class="code" href="scan_8cs.html#acdef7a1fd863a6d3770c1268cb06add3">main</a>()</div><div class="line">{</div><div class="line">    uint ident = gl_GlobalInvocationID.x;</div><div class="line">    output_data.elements[ident] = input_data0.elements[ident] * input_data1.elements[ident];</div><div class="line">}</div></div><!-- fragment --><h1><a class="anchor" id="computeImageLoadStore"></a>
Reading and writing to textures</h1>
<p>Similarly to the situation with buffer objects before, textures have been read-only. The standard way to write to a texture has been via framebuffer objects and fragment shading. For compute, a new and more direct interface to deal with writeable textures is introduced.</p>
<p>We have had terminology like a texture and sampler before, but to expose writeable textures a shader <code>image</code> is introduced. <a class="el" href="class_shader.html">Shader</a> images have support for random-access reads (like <code>texelFetch</code>), and random access writes. An interesting feature is that they also support reinterpreting the underlying datatype. Unlike regular textures, shader images support no filtering, and as they are basically raw texel access, the underlying datatype can be reinterpreted however the shader wants. The restriction is that the actual texture format and reinterpreted format must have the same size.</p>
<p>Layering is also supported. This means that a cube map, 2D texture array or 3D texture can be bound and the shader has full access to any cube face, array index or 3D texture slice. It is also possible to disable layering and only bind a single layer as a plain 2D image.</p>
<h2><a class="anchor" id="computeImageBinding"></a>
Binding a shader image</h2>
<p>Binding a shader image is similar to binding a texture.</p>
<div class="fragment"><div class="line">glBindImageTexture(unit, <a class="code" href="gl2ext_8h.html#ab21590c4736d1459a5a0674a42b5a655">texture</a>, <a class="code" href="gl2ext_8h.html#a2b536fca24f51d6a849aed325793e661">level</a>, <a class="code" href="gl2ext_8h.html#a12d02feb44c56035bf1af92d3e6a1a3b">layered</a>, <a class="code" href="gl2ext_8h.html#ab2fb5ac19001403d8210b239a4cc0a8b">layer</a>, <a class="code" href="gl2ext_8h.html#a9fb81ef401f3cb865f7b2f1bb059f7d7">access</a>, <a class="code" href="gl2ext_8h.html#a71a65ffd977afe9c3fef116a5bc9ee27">format</a>);</div><div class="line"></div><div class="line"><span class="comment">// For example</span></div><div class="line">glBindImageTexture(0,             <span class="comment">/* unit, note that we&#39;re not offsetting GL_TEXTURE0 */</span></div><div class="line">                   <a class="code" href="gl2ext_8h.html#ab21590c4736d1459a5a0674a42b5a655">texture</a>,       <span class="comment">/* a 2D texture for example */</span></div><div class="line">                   0,             <span class="comment">/* miplevel */</span></div><div class="line">                   GL_FALSE,      <span class="comment">/* we cannot use layered */</span></div><div class="line">                   0,             <span class="comment">/* this is ignored */</span></div><div class="line">                   GL_WRITE_ONLY, <span class="comment">/* we&#39;re only writing to it */</span></div><div class="line">                   GL_R32F        <span class="comment">/* interpret format as 32-bit float */</span>);</div></div><!-- fragment --><p>In the shader code, we would do something like:</p>
<div class="fragment"><div class="line"><a class="code" href="scan_8cs.html#abc5bc4dfe74a37a3a6850b9a15630dc7">layout</a>(r32f <span class="comment">/* Format, must match parameter in glBindImageTexture() */</span>, binding = 0) writeonly <a class="code" href="_compute_particles_2jni_2common_2glutil_8cpp.html#a2c5c3c4ce30783b590dd30b1060b7b38">uniform</a> highp image2D uImage;</div></div><!-- fragment --><p>In GLSL, we can now use <code>imageLoad()</code>, <code>imageStore()</code> and <code><a class="el" href="gl2ext_8h.html#af17aef68eaddfa6109474d953fc65888">imageSize()</a></code>.</p>
<div class="fragment"><div class="line">imageStore(uImage, <a class="code" href="_f_f_t_ocean_water_2jni_2vector__math_8h.html#ac8de76610b426f3ba8c071f5011dd15e">ivec2</a>(28, 39), <a class="code" href="structvec4.html">vec4</a>(1.0)); <span class="comment">// Random access texture writes!</span></div></div><!-- fragment --><dl class="section note"><dt>Note</dt><dd>A common mistake is to attempt to use <code>glUniform1i()</code> to bind shader images to a particular "unit" like with regular samplers. This is not supported, and you should use <code>layout(binding = UNIT)</code> in the shader code instead. This is the modern OpenGL (ES) way of doing things anyways.</dd>
<dd>
A very important restriction for using shader images is that the underlying texture must have been allocated using "immutable" storage, i.e. via <code>glTexStorage*()</code>-like functions, and not <code>glTexImage2D()</code>.</dd></dl>
<h1><a class="anchor" id="computeShared"></a>
Sharing memory between threads in same work group</h1>
<p>A major feature of compute is that since we have the concept of a work group, we can now give the work group some shared memory which can be used by every thread in the work group. This allows compute shader threads to share their computation with other threads which can make or break certain parallel algorithms.</p>
<ul>
<li>Shared memory is limited in size.</li>
<li>Implementations must support at least 16 KiB worth of storage for a single work group.</li>
<li>Shared memory is uninitialized, and not persistent.</li>
<li>It is not backed by buffer objects and only serves as scratch memory for the execution of a work group.</li>
</ul>
<p>A nice use case for shared memory is that it's sometimes possible to perform multi-pass algorithms in a single pass instead by using shared memory to store data between passes. Shared memory is typically backed by either cache or specialized fast local memory. Multi-pass approaches using fragment shaders need to flush out results to textures every pass, which can get very bandwidth intensive.</p>
<p>To declare shared memory for a compute work group, do this:</p>
<div class="fragment"><div class="line">shared <span class="keywordtype">float</span> shareData[1024]; <span class="comment">// Shared between all threads in work group.</span></div><div class="line"></div><div class="line"><span class="keywordtype">void</span> <a class="code" href="scan_8cs.html#acdef7a1fd863a6d3770c1268cb06add3">main</a>()</div><div class="line">{</div><div class="line">    <span class="comment">// Shader code here ...</span></div><div class="line">}</div></div><!-- fragment --><p>To properly make use of shared memory however, we will need to introduce some new <a class="el" href="computeIntro.html#computeSync">synchronization primitives</a> first.</p>
<h1><a class="anchor" id="computeAtomics"></a>
Atomic operations</h1>
<p>With compute shaders, multiple threads can perform operations on the same memory location. Without some new atomic primitives, accessing such memory safely and correct would be impossible.</p>
<ul>
<li>Atomic addition/subtraction</li>
<li>Atomic or/xor/and</li>
<li>Atomic maximum/minimum</li>
<li>Atomic exchange</li>
<li>Atomic compare exchange</li>
</ul>
<p>Atomic operations fetch the memory location, perform the operation and write back to memory atomically. Thus, multiple threads can access the same memory without data races. Atomic operations are supported for uint and int datatypes. Atomic operations always return the value that was in memory before applying the operation in question.</p>
<p>There are two interfaces for using atomics in OpenGL ES 3.1, explained below.</p>
<h2><a class="anchor" id="computeAtomicCounters"></a>
Atomic counters</h2>
<p>The first interface is the older atomic counters interface. It is a reduced interface which only supports basic increments and decrements.</p>
<p>In a shader, you can declare an <code>atomic_uint</code> like this:</p>
<div class="fragment"><div class="line"><a class="code" href="scan_8cs.html#abc5bc4dfe74a37a3a6850b9a15630dc7">layout</a>(binding = 0, <a class="code" href="gl2ext_8h.html#a56ae4f2c17db21521c5849fe34735fb2">offset</a> = 0) <a class="code" href="_compute_particles_2jni_2common_2glutil_8cpp.html#a2c5c3c4ce30783b590dd30b1060b7b38">uniform</a> atomic_uint atomicCounter;</div><div class="line"></div><div class="line"><span class="keywordtype">void</span> main()</div><div class="line">{</div><div class="line">    uint previous = atomicCounterIncrement(atomicCounter);</div><div class="line">}</div></div><!-- fragment --><p>Atomic counters are backed by a buffer object <code>GL_ATOMIC_COUNTER_BUFFER</code>. Just like uniform buffers, they are indexed buffers. To bind an indexed buffer, use</p>
<div class="fragment"><div class="line">glBindBufferBase(GL_ATOMIC_COUNTER_BUFFER, index, buffer_object);</div></div><!-- fragment --><p>or</p>
<div class="fragment"><div class="line">glBindBufferRange(GL_ATOMIC_COUNTER_BUFFER, index, buffer_object, <a class="code" href="gl2ext_8h.html#a56ae4f2c17db21521c5849fe34735fb2">offset</a>, <a class="code" href="gl2ext_8h.html#a9f139c614d49f2a707b6037305b0fec0">size</a>);</div></div><!-- fragment --><dl class="section note"><dt>Note</dt><dd>Any OpenGL buffer can be bound to <code>GL_ATOMIC_COUNTER_BUFFER</code>. Note that there are restrictions to the number of counters you can use.</dd></dl>
<h2><a class="anchor" id="computeAtomicSSBO"></a>
Atomic operations on SSBOs and shared memory</h2>
<p>A more flexible interface to atomics is when using shared memory or SSBOs. Various <code>atomic*()</code> functions are provided which accept variables backed by shared or SSBO memory.</p>
<p>For example:</p>
<div class="fragment"><div class="line">shared uint sharedVariable;</div><div class="line"><a class="code" href="scan_8cs.html#abc5bc4dfe74a37a3a6850b9a15630dc7">layout</a>(std430, binding = 0) <a class="code" href="gl2ext_8h.html#a7fc54503e1a1cf98d128b839ebc0b4d0">buffer</a> <a class="code" href="namespace_g_l_f_f_t.html#ab2687fef8a775901f5fb093657631cb1ae5acf46f7696870f1a14d4ee79a846c0">SSBO</a> {</div><div class="line">    uint variables[];</div><div class="line">};</div><div class="line"></div><div class="line"><span class="keywordtype">void</span> <a class="code" href="scan_8cs.html#acdef7a1fd863a6d3770c1268cb06add3">main</a>()</div><div class="line">{</div><div class="line">    uint previousShared = atomicAdd(sharedVariable, 42u);</div><div class="line">    uint previousSSBO   = atomicMax(variables[12], 11u);</div><div class="line">}</div></div><!-- fragment --><h2><a class="anchor" id="computeAtomicImage"></a>
Atomic operations on shader images</h2>
<p>With an extension to OpenGL ES 3.1, <code>GL_OES_shader_image_atomic</code>, atomic operations are supported on shader images as well.</p>
<h1><a class="anchor" id="computeMemory"></a>
Synchronizing memory transactions</h1>
<p>OpenGL ES from an API standpoint is an in-order model. The API <b>appears</b> to execute GL commands as-if every command is completed immediately before moving on to the next GL command. Of course, any reasonable OpenGL ES implementation will not do this, and opt for a buffered and/or deferred approach. In addition, for various hazard scenarios like reading from a texture after rendering a scene to it, the driver needs to ensure proper synchronization, etc. Users of OpenGL ES do not have to think about these low-level details. The main reason why this can be practical from an API standpoint is that up until now, the API have had full control of where shaders write data. Either we wrote data to textures via FBOs, or to buffers with transform feedback. The driver could track which data has been touched and add the extra synchronization needed to operate correctly.</p>
<p>With compute however, the model changes somewhat. Now, compute shaders can write to SSBOs, images, atomics and shared memory. Whenever we perform such writes, we need to ensure proper synchronization ourselves.</p>
<h2><a class="anchor" id="computeCoherent"></a>
Coherent and various memory qualifiers</h2>
<p>Being able to have writes from one thread be visible to another thread running in parallel requires coherent memory. We need some new qualifiers to express how we are going to access the memory, and OpenGL ES 3.1 defines these new qualifiers.</p>
<ul>
<li>coherent</li>
<li>writeonly</li>
<li>readonly</li>
<li>volatile</li>
<li>restrict</li>
</ul>
<p>To use one or multiple qualifiers, we can apply them to SSBOs and shader images like this:</p>
<div class="fragment"><div class="line"><span class="comment">// SSBO</span></div><div class="line"><a class="code" href="scan_8cs.html#abc5bc4dfe74a37a3a6850b9a15630dc7">layout</a>(std430, binding = 0) writeonly coherent <a class="code" href="gl2ext_8h.html#a7fc54503e1a1cf98d128b839ebc0b4d0">buffer</a> <a class="code" href="namespace_g_l_f_f_t.html#ab2687fef8a775901f5fb093657631cb1ae5acf46f7696870f1a14d4ee79a846c0">SSBO</a> {</div><div class="line">    <span class="keywordtype">float</span> coherentVariable;</div><div class="line">};</div><div class="line"></div><div class="line"><span class="comment">// Image</span></div><div class="line"><a class="code" href="scan_8cs.html#abc5bc4dfe74a37a3a6850b9a15630dc7">layout</a>(r32f, binding = 0) restrict readonly <a class="code" href="_compute_particles_2jni_2common_2glutil_8cpp.html#a2c5c3c4ce30783b590dd30b1060b7b38">uniform</a> highp image2D uImage;</div></div><!-- fragment --><h3><a class="anchor" id="computeQualifierCoherent"></a>
coherent</h3>
<p>A variable declared coherent means that a write to that variable will eventually be made visible to other shader invocations in the same GL command. This is only useful if you expect that other threads are going to read the data that one thread will write. Threads which are reading data from coherent writes must also read from variables marked as coherent.</p>
<dl class="section note"><dt>Note</dt><dd>Coherent qualifier should not be used if the data written by shaders are to be consumed in a different GL command. See <a class="el" href="computeIntro.html#computeAPIBarrier">API level memory barriers</a> for that case.</dd>
<dd>
Shared memory as you'd might expect is implicitly declared with coherent qualifiers, since its purpose is precisely to share data between threads. While using the coherent qualifier itself is fairly uncommon, the rules are still important to know since shared memory is coherent.</dd></dl>
<h3><a class="anchor" id="computeWriteOnly"></a>
writeonly/readonly</h3>
<p>These are designed to express read-only or write-only behavior. Atomic operations both read and write variables, and variables cannot be declared with either if atomics are used.</p>
<h3><a class="anchor" id="computeVolatileRestrict"></a>
volatile/restrict</h3>
<p>These are fairly obscure. Their meanings are the same as in C. Restrict expresses that buffers or images do not alias each other, while volatile means buffer storage can change at any time, and must be reloaded every time.</p>
<h2><a class="anchor" id="computeAPIBarrier"></a>
API level memory barriers</h2>
<p>Consider a probable use of compute where we're computing a vertex buffer and drawing the result:</p>
<div class="fragment"><div class="line">glBindBufferBase(GL_SHADER_STORAGE_BUFFER, 0, <a class="code" href="gl2ext_8h.html#a7fc54503e1a1cf98d128b839ebc0b4d0">buffer</a>);</div><div class="line">glUseProgram(update_vbo_program);</div><div class="line">glDispatchCompute(GROUPS, 1, 1); <span class="comment">// &lt;-- Write to buffer</span></div><div class="line"></div><div class="line">glUseProgram(render_program);</div><div class="line">glBindVertexArray(vertex_array);</div><div class="line">glDrawElements(GL_TRIANGLES, ...); <span class="comment">// &lt;-- Read from buffer</span></div></div><!-- fragment --><p>If this were render-to-texture or similar, code like this would be correct since the OpenGL ES driver ensures correct synchronization. However, since we wrote to an SSBO in a compute shader, we need to ensure that our writes are properly synchronized with the rest of OpenGL ES ourselves.</p>
<p>To do this, we use a new function, <code>glMemoryBarrier()</code> and our corrected version looks like:</p>
<div class="fragment"><div class="line">glBindBufferBase(GL_SHADER_STORAGE_BUFFER, 0, <a class="code" href="gl2ext_8h.html#a7fc54503e1a1cf98d128b839ebc0b4d0">buffer</a>);</div><div class="line">glUseProgram(update_vbo_program);</div><div class="line">glDispatchCompute(NUM_WORK_GROUPS, 1, 1); <span class="comment">// &lt;-- Write to buffer</span></div><div class="line"></div><div class="line"><span class="comment">// Ensure that writes to buffer are visible to subsequent GL commands which try to read from it.</span></div><div class="line"><span class="comment">// Essentially, it tells the GPU to flush and/or invalidate its appropriate caches.</span></div><div class="line">glMemoryBarrier(GL_VERTEX_ATTRIB_ARRAY_BARRIER_BIT);</div><div class="line"></div><div class="line">glUseProgram(render_program);</div><div class="line">glBindVertexArray(vertex_array);</div><div class="line">glDrawElements(GL_TRIANGLES, ...); <span class="comment">// &lt;-- Read from buffer</span></div></div><!-- fragment --><p>It's important to remember the semantics of <code>glMemoryBarrier()</code>. As argument it takes a bitfield of various buffer types. We specify how we will <b>read</b> data after the memory barrier. In this case, we are writing the buffer via an SSBO, but we're reading it when we're using it as a vertex buffer, hence <code>GL_VERTEX_ATTRIB_ARRAY_BARRIER_BIT</code>.</p>
<p>Another detail is that we only need a memory barrier here. We do not need some kind of "execution barrier" for the compute dispatch itself.</p>
<h2><a class="anchor" id="computeShaderBarrier"></a>
Shader language memory barriers</h2>
<p>While the API level memory barriers order memory accesses across GL commands, we also need some shader language barriers to order memory accesses within a single dispatch.</p>
<p>To understand memory barriers, we first need to consider memory ordering. An important problem with multi-threaded programming is that while memory transactions within a single thread might happen as expected, when other threads see the data written by the thread, the order of which the memory writes become visible might not be well defined depending on the architecture. In the CPU space, this problem also exists, where it's often referred to as "weakly ordered memory".</p>
<p>To fully grasp the consequences of weakly ordered memory is a long topic on its own. The section here serves to give some insight as to why ordering matters, and why we need to think about memory ordering when we want to share data with other threads running in parallel.</p>
<p>To illustrate why ordering matters, we can consider two threads in this classic example. Thread 1 is a producer which writes data, and thread 2 consumes it.</p>
<div class="fragment"><div class="line">shared <span class="keywordtype">int</span> A;</div><div class="line">shared <span class="keywordtype">int</span> B;</div><div class="line"></div><div class="line"><span class="comment">// Assume A and B are initially 0 and that thread A and B are running in parallel.</span></div><div class="line"></div><div class="line"><span class="comment">// Thread 1</span></div><div class="line">A = 1;</div><div class="line">B = 1;</div><div class="line"></div><div class="line"><span class="comment">// Thread 2</span></div><div class="line"><span class="keywordtype">int</span> readB = B;</div><div class="line"><span class="keywordtype">int</span> readA = A;</div><div class="line"></div><div class="line"><span class="keywordflow">if</span> (readA == 0 &amp;&amp; readB == 0)</div><div class="line">{</div><div class="line">    <span class="comment">// This makes sense. Thread 2 might have read A and B before thread 1 completed any of its writes.</span></div><div class="line">}</div><div class="line"><span class="keywordflow">else</span> <span class="keywordflow">if</span> (readA == 1 &amp;&amp; readB == 0)</div><div class="line">{</div><div class="line">    <span class="comment">// This makes sense, we might have read A and B in-between the write to A and B in thread 1.</span></div><div class="line">}</div><div class="line"><span class="keywordflow">else</span> <span class="keywordflow">if</span> (readA == 1 &amp;&amp; readB == 1)</div><div class="line">{</div><div class="line">    <span class="comment">// This also makes sense. Thread 1 have completed both its writes before thread 2 read any of them.</span></div><div class="line">}</div><div class="line"><span class="keywordflow">else</span> <span class="keywordflow">if</span> (readA == 0 &amp;&amp; readB == 1)</div><div class="line">{</div><div class="line">    <span class="comment">// How can this happen? It can ...</span></div><div class="line">}</div></div><!-- fragment --><p>Even if thread 1 wrote to A, then B, it is possible that the memory system completes the write to B first, then A. If thread 2 reads B and A with just the right timing, the odd-ball case above is possible.</p>
<p>To resolve this case, we need to employ memory barriers to tell the memory system that a strict ordering guarantee is required. OpenGL ES defines several memory barriers.</p>
<ul>
<li><code>memoryBarrier()</code></li>
<li><code>memoryBarrierShared()</code></li>
<li><code>memoryBarrierImage()</code></li>
<li><code>memoryBarrierBuffer()</code></li>
<li><code>memoryBarrierAtomicCounter()</code></li>
<li><code>groupMemoryBarrier()</code></li>
</ul>
<p>The <code>memoryBarrier*()</code> functions control memory ordering for a particular memory type. <code>memoryBarrier()</code> enforces ordering for all memory accesses. <code>groupMemoryBarrier()</code> enforces memory ordering like <code>memoryBarrier()</code>, but only for threads in the same work group. All memory barriers except for <code>groupMemoryBarrier()</code> and <code>memoryBarrierShared()</code> enforce ordering for all threads in the compute dispatch.</p>
<p>The memory barrier ensures that all memory transactions before the barrier must complete before proceeding. Memory accesses below the barrier cannot be moved over the barrier.</p>
<p>Looking at our example, we can now fix it like this:</p>
<div class="fragment"><div class="line"><span class="comment">// Thread 1</span></div><div class="line">A = 1;</div><div class="line">memoryBarrierShared(); <span class="comment">// Write to B cannot complete until A is completed.</span></div><div class="line">B = 1;</div><div class="line"></div><div class="line"><span class="comment">// Thread 2</span></div><div class="line"><span class="keywordtype">int</span> readB = B;</div><div class="line">memoryBarrierShared(); <span class="comment">// Reads from A cannot happen before we&#39;ve read B.</span></div><div class="line"><span class="keywordtype">int</span> readA = A;</div><div class="line"></div><div class="line"><span class="keywordflow">if</span> (readA == 0 &amp;&amp; readB == 1)</div><div class="line">{</div><div class="line">    <span class="comment">// This case is now impossible. If B == 1, we know that the write to A must have happened.</span></div><div class="line">    <span class="comment">// Since we are guaranteed to read A after B, we must read A == 1 as well.</span></div><div class="line">}</div></div><!-- fragment --><p>While ordering scenarios like these are rarely relevant for compute, memory barriers in OpenGL ES also ensure visibility of coherent writes. If a thread is writing to coherent variables and we want to ensure that our writes become visible to other threads, we need memory barriers. For example:</p>
<div class="fragment"><div class="line">write_stuff_to_shared_memory();</div><div class="line"></div><div class="line"><span class="comment">// We can conceptually see this as &quot;flush out my writes to shared memory now&quot;.</span></div><div class="line"><span class="comment">// If other threads try to read from shared memory after this returns, we are guaranteed to read the correct values.</span></div><div class="line">memoryBarrierShared();</div></div><!-- fragment --><dl class="section note"><dt>Note</dt><dd>While memory barriers ensure that writes become visible, this does not mean that omitting a memory barrier guarantees that writes never become visible. If two threads happen to share the same caches, the writes would likely become visible anyways.</dd></dl>
<h1><a class="anchor" id="computeSync"></a>
Synchronizing execution of threads</h1>
<p>Memory barriers only ensure ordering for memory, not execution. Parallel algorithms often require some kind of execution synchronization as well.</p>
<p>A cornerstone of GPU compute is the ability to synchronize threads in the same workgroup. By having fine-grained synchronization of multiple threads, we are able to implement algorithms where we can safely know that other threads in the work group have done their tasks.</p>
<p>For example, let's assume a case where we want to read some data from an SSBO, perform some computation on the data and share the results with the other threads in the work group.</p>
<div class="fragment"><div class="line"><span class="preprocessor">#version 310 es</span></div><div class="line"><a class="code" href="scan_8cs.html#abc5bc4dfe74a37a3a6850b9a15630dc7">layout</a>(local_size_x = 128) in; <span class="comment">// Work group of 128 threads.</span></div><div class="line"></div><div class="line"><span class="comment">// Allow ping-ponging between two buffers.</span></div><div class="line">shared <a class="code" href="structvec4.html">vec4</a> someSharedData0[128];</div><div class="line">shared <a class="code" href="structvec4.html">vec4</a> someSharedData1[128];</div><div class="line"></div><div class="line"><a class="code" href="scan_8cs.html#abc5bc4dfe74a37a3a6850b9a15630dc7">layout</a>(std430, binding = 0) readonly <a class="code" href="gl2ext_8h.html#a7fc54503e1a1cf98d128b839ebc0b4d0">buffer</a> InputData {</div><div class="line">    <a class="code" href="structvec4.html">vec4</a> someInputData[];</div><div class="line">};</div><div class="line"></div><div class="line"><a class="code" href="scan_8cs.html#abc5bc4dfe74a37a3a6850b9a15630dc7">layout</a>(std430, binding = 1) writeonly <a class="code" href="gl2ext_8h.html#a7fc54503e1a1cf98d128b839ebc0b4d0">buffer</a> OutputData {</div><div class="line">    <a class="code" href="structvec4.html">vec4</a> someOutputData[];</div><div class="line">};</div><div class="line"></div><div class="line"><a class="code" href="structvec4.html">vec4</a> perform_computation(<a class="code" href="structvec4.html">vec4</a> <a class="code" href="gl2ext_8h.html#a740d7f00b044f54a556c7208e01f9f02">data</a>)</div><div class="line">{</div><div class="line">    <span class="keywordflow">return</span> sin(data);</div><div class="line">}</div><div class="line"></div><div class="line"><a class="code" href="structvec4.html">vec4</a> some_arbitrary_work(<a class="code" href="structvec4.html">vec4</a> <a class="code" href="gl2ext_8h.html#ac8729153468b5dcf13f971b21d84d4e5">a</a>, <a class="code" href="structvec4.html">vec4</a> <a class="code" href="gl2ext_8h.html#a6eba317e3cf44d6d26c04a5a8f197dcb">b</a>)</div><div class="line">{</div><div class="line">    <span class="keywordflow">return</span> <a class="code" href="structvec4.html">vec4</a>(a.xy * b.yx, a.zw * b.wz);</div><div class="line">}</div><div class="line"></div><div class="line"><span class="keywordtype">void</span> <a class="code" href="scan_8cs.html#acdef7a1fd863a6d3770c1268cb06add3">main</a>()</div><div class="line">{</div><div class="line">    <span class="comment">// If you are very lucky, this would work ...</span></div><div class="line"></div><div class="line">    someSharedData0[gl_LocalInvocationIndex] = perform_computation(someInputData[gl_GlobalInvocationID.x]);</div><div class="line"></div><div class="line">    <span class="comment">// Where is memory barrier?</span></div><div class="line">    </div><div class="line">    <span class="comment">// Here we want to use the results that other threads have computed and do something useful.</span></div><div class="line">    <span class="comment">// Note the alternation between two arrays.</span></div><div class="line"></div><div class="line">    <span class="comment">// 1st pass.</span></div><div class="line">    someSharedData1[gl_LocalInvocationIndex] =</div><div class="line">        some_arbitrary_work(someSharedData0[gl_LocalInvocationIndex], someSharedData0[(gl_LocalInvocationIndex + 15u) &amp; 127u]);</div><div class="line"></div><div class="line">    <span class="comment">// Again, use results from other threads.</span></div><div class="line">    <span class="comment">// 2nd pass.</span></div><div class="line">    someSharedData0[gl_LocalInvocationIndex] =</div><div class="line">        some_arbitrary_work(someSharedData1[gl_LocalInvocationIndex], someSharedData1[(gl_LocalInvocationIndex + 15u) &amp; 127u]);</div><div class="line"></div><div class="line">    <span class="comment">// Again, use results from other threads.</span></div><div class="line">    <span class="comment">// 3rd pass, write out results to buffer.</span></div><div class="line">    someOutputData[gl_LocalInvocationIndex] =</div><div class="line">        some_arbitrary_work(someSharedData0[gl_LocalInvocationIndex], someSharedData0[(gl_LocalInvocationIndex + 15u) &amp; 127u]);</div><div class="line">}</div></div><!-- fragment --><p>In this sample, we're missing proper synchronization. For example, we have a fundamental problem that we aren't guaranteed that other threads in the work group have executed <code>perform_computation()</code> and written out the result to <code>someSharedData0</code>. If we let one thread proceed with execution prematurely, we will read garbage, and the computation will obviously be wrong. To solve this problem we need to employ memory barriers and execution barriers.</p>
<div class="fragment"><div class="line"><span class="preprocessor">#version 310 es</span></div><div class="line"><a class="code" href="scan_8cs.html#abc5bc4dfe74a37a3a6850b9a15630dc7">layout</a>(local_size_x = 128) in; <span class="comment">// Work group of 128 threads.</span></div><div class="line"></div><div class="line"><span class="comment">// Allow ping-ponging between two buffers.</span></div><div class="line">shared <a class="code" href="structvec4.html">vec4</a> someSharedData0[128];</div><div class="line">shared <a class="code" href="structvec4.html">vec4</a> someSharedData1[128];</div><div class="line"></div><div class="line"><a class="code" href="scan_8cs.html#abc5bc4dfe74a37a3a6850b9a15630dc7">layout</a>(std430, binding = 0) readonly <a class="code" href="gl2ext_8h.html#a7fc54503e1a1cf98d128b839ebc0b4d0">buffer</a> InputData {</div><div class="line">    <a class="code" href="structvec4.html">vec4</a> someInputData[];</div><div class="line">};</div><div class="line"></div><div class="line"><a class="code" href="scan_8cs.html#abc5bc4dfe74a37a3a6850b9a15630dc7">layout</a>(std430, binding = 1) writeonly <a class="code" href="gl2ext_8h.html#a7fc54503e1a1cf98d128b839ebc0b4d0">buffer</a> OutputData {</div><div class="line">    <a class="code" href="structvec4.html">vec4</a> someOutputData[];</div><div class="line">};</div><div class="line"></div><div class="line"><a class="code" href="structvec4.html">vec4</a> perform_computation(<a class="code" href="structvec4.html">vec4</a> <a class="code" href="gl2ext_8h.html#a740d7f00b044f54a556c7208e01f9f02">data</a>)</div><div class="line">{</div><div class="line">    <span class="keywordflow">return</span> sin(data);</div><div class="line">}</div><div class="line"></div><div class="line"><a class="code" href="structvec4.html">vec4</a> some_arbitrary_work(<a class="code" href="structvec4.html">vec4</a> <a class="code" href="gl2ext_8h.html#ac8729153468b5dcf13f971b21d84d4e5">a</a>, <a class="code" href="structvec4.html">vec4</a> <a class="code" href="gl2ext_8h.html#a6eba317e3cf44d6d26c04a5a8f197dcb">b</a>)</div><div class="line">{</div><div class="line">    <span class="keywordflow">return</span> <a class="code" href="structvec4.html">vec4</a>(a.xy * b.yx, a.zw * b.wz);</div><div class="line">}</div><div class="line"></div><div class="line"><span class="keywordtype">void</span> synchronize()</div><div class="line">{</div><div class="line">    <span class="comment">// Ensure that memory accesses to shared variables complete.</span></div><div class="line">    memoryBarrierShared();</div><div class="line"></div><div class="line">    <span class="comment">// Every thread in work group must reach this barrier before any other thread can continue.</span></div><div class="line">    barrier();</div><div class="line">}</div><div class="line"></div><div class="line"><span class="keywordtype">void</span> <a class="code" href="scan_8cs.html#acdef7a1fd863a6d3770c1268cb06add3">main</a>()</div><div class="line">{</div><div class="line">    someSharedData0[gl_LocalInvocationIndex] = perform_computation(someInputData[gl_GlobalInvocationID.x]);</div><div class="line"></div><div class="line">    synchronize();</div><div class="line"></div><div class="line">    <span class="comment">// We are now guaranteed that all threads in the work group have completed their work, and that their shared memory writes</span></div><div class="line">    <span class="comment">// are visible to us. We can now proceed with the computation.</span></div><div class="line">   </div><div class="line">    <span class="comment">// It&#39;s important that we&#39;re writing to a separate shared array here,</span></div><div class="line">    <span class="comment">// otherwise our newly computed values could stomp on the data that other threads are trying to read.</span></div><div class="line">    someSharedData1[gl_LocalInvocationIndex] =</div><div class="line">        some_arbitrary_work(someSharedData0[gl_LocalInvocationIndex], someSharedData0[(gl_LocalInvocationIndex + 15u) &amp; 127u]);</div><div class="line"></div><div class="line">    synchronize();</div><div class="line"></div><div class="line">    someSharedData0[gl_LocalInvocationIndex] =</div><div class="line">        some_arbitrary_work(someSharedData1[gl_LocalInvocationIndex], someSharedData1[(gl_LocalInvocationIndex + 15u) &amp; 127u]);</div><div class="line"></div><div class="line">    synchronize();</div><div class="line"></div><div class="line">    someOutputData[gl_LocalInvocationIndex] =</div><div class="line">        some_arbitrary_work(someSharedData0[gl_LocalInvocationIndex], someSharedData0[(gl_LocalInvocationIndex + 15u) &amp; 127u]);</div><div class="line">}</div></div><!-- fragment --><dl class="section note"><dt>Note</dt><dd>Many tutorials assume that calling <code>barrier()</code> also implies that shared memory is synchronized. While this is often the case from an implementation point of view, the OpenGL ES specification is not as clear on this and to avoid potential issues, use of a proper <code>memoryBarrierShared()</code> before <code>barrier()</code> is <b>highly</b> recommended. For any other memory type than shared, the specification is very clear on that the approprimate memory barrier must be used.</dd></dl>
<h2><a class="anchor" id="computeBarrierFlowControl"></a>
Flow control and barrier()</h2>
<p><code>barrier()</code> is a quite special function due to its synchronization properties. If one of the threads in the work group does not hit the barrier(), it conceptually means that no other thread can ever continue, and we would have a deadlock.</p>
<p>These situations can arise in divergent code, and it's necessary for the programmer to ensure that either every thread calls the barrier, or no threads call it. It's legal to call barrier() in a branch (or loop), as long as the flow control is dynamically uniform. E.g.:</p>
<div class="fragment"><div class="line"><span class="keywordflow">if</span> (someUniform &gt; 1.0)</div><div class="line">{</div><div class="line">    <span class="comment">// Fine, since this condition will fail or pass for every thread.</span></div><div class="line">    barrier();</div><div class="line">}</div></div><!-- fragment --><div class="fragment"><div class="line"><span class="keywordflow">if</span> (someVariable &gt; 1.0)</div><div class="line">{</div><div class="line">    <span class="comment">// Can be problematic, unless the branch is guaranteed to be taken or not for every thread the same way.</span></div><div class="line">    barrier();</div><div class="line">}</div></div><!-- fragment --><h1><a class="anchor" id="computeVertexFragment"></a>
Compute-like functionality in other graphics stages</h1>
<p>Compute-like functionality such as SSBOs, shader image load/store and atomic counters are <b>optionally</b> supported in vertex and fragment shaders as well in OpenGL ES 3.1. To test if these features are supported, various <code>glGetIntegerv()</code> queries tells the application if these features are supported.</p>
<ul>
<li><code>GL_MAX_*_ATOMIC_COUNTERS</code></li>
<li><code>GL_MAX_*_SHADER_STORAGE_BLOCKS</code></li>
<li><code>GL_MAX_*_IMAGE_UNIFORMS</code></li>
</ul>
<p>where <code>*</code> can be replaced with the appropriate shader stage. In OpenGL ES 3.1, these values are 0 if not supported by the implementation.</p>
<h2><a class="anchor" id="computeBarrierByRegion"></a>
glMemoryBarrierByRegion()</h2>
<p><code>glMemoryBarrierByRegion()</code> is a special variant of <code>glMemoryBarrier()</code> which only applies for fragment shaders. It works the same way as <code>glMemoryBarrier()</code> except that it only guarantees memory ordering for fragments belonging to the same "region" of the framebuffer. The region is implementation defined, and can be as small as one pixel.</p>
<p>This can be useful especially for tiled GPU architectures. Consider:</p>
<div class="fragment"><div class="line">draw_call_1(); <span class="comment">// Write to shader image load store.</span></div><div class="line">glMemoryBarrier(GL_SHADER_IMAGE_ACCESS_BARRIER_BIT);</div><div class="line">draw_call_2(); <span class="comment">// Use results from first draw call.</span></div></div><!-- fragment --><p>Since <code>glMemoryBarrier()</code> must guarantee visibility, we need to wait for every fragment in draw_call_1 to complete to ensure that our ordering guarantee is met. Since the fragments can hit anywhere in the entire framebuffer, this effectively means that we have to flush out our scene to memory, which we really want to avoid on tiled architectures.</p>
<p>However, if we only care about ordering between fragments which hit the same <b>region</b> (pixel in framebuffer). We can avoid flushing out tile buffers to memory.</p>
<div class="fragment"><div class="line">draw_call_1(); <span class="comment">// Write to shader image load store.</span></div><div class="line">glMemoryBarrierByRegion(GL_SHADER_IMAGE_ACCESS_BARRIER_BIT); <span class="comment">// Relaxed memory barrier.</span></div><div class="line">draw_call_2(); <span class="comment">// Use results from first draw call.</span></div></div><!-- fragment --><h2><a class="anchor" id="computeEarlyZ"></a>
Force early-Z in fragment shader</h2>
<p>OpenGL ES 3.1 defines a model where per-fragment tests like depth testing happen <b>after</b> fragment shader execution. This is needed to accomodate cases where the fragment shader modifies depth.</p>
<p>Modifying depth in the fragment shaders however is uncommon, and GPUs will tend to avoid executing the fragment shader altogether if it can since it already knows the fragment depth and can do the depth test early.</p>
<p>With random access writes in fragment shaders, the situation becomes more complicated. We could do early-Z because there were no side effects in the fragment shader, but this model breaks down once side effects like shader image load/store is used. Since early-Z is so important, we can now force early depth testing in the fragment shader.</p>
<div class="fragment"><div class="line"><span class="preprocessor">#version 310 es</span></div><div class="line"><span class="preprocessor">layout(early_fragment_tests) in;</span></div></div><!-- fragment --> </div></div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="tutorials.html">Tutorials</a></li>
    <li class="footer">
        <a class="copyright" href="http://www.arm.com/">(C) ARM Ltd. 2017</a>
    </li>
  </ul>
</div>
</body>
</html>
